{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dFDRJR3hsKV4"
      },
      "outputs": [],
      "source": [
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\HP\\anaconda3\\envs\\pose_env\\python.exe\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mbSfRTD3sKYh"
      },
      "outputs": [],
      "source": [
        "model_path = 'pose_landmarker_lite.task'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iqsrtQQxvg_L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN4Q7RKZsKa1",
        "outputId": "20a5b8a5-934e-4f3e-c928-f67e9c31b835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature shape: (481, 132)\n",
            "Labels shape: (481,)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "\n",
        "BaseOptions = mp.tasks.BaseOptions\n",
        "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
        "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
        "VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "options = PoseLandmarkerOptions(\n",
        "    base_options=BaseOptions(model_asset_path=model_path),\n",
        "    running_mode=VisionRunningMode.IMAGE\n",
        ")\n",
        "\n",
        "dataset_path = \"C:/Users/HP/Desktop/SEM 6/Minor project 2/Book-Recommendation-System-master/Yoga Pose Detector/TRAIN\"\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "with PoseLandmarker.create_from_options(options) as landmarker:\n",
        "    for label_folder in os.listdir(dataset_path):\n",
        "\n",
        "        label_path = os.path.join(dataset_path, label_folder)\n",
        "        if not os.path.isdir(label_path):\n",
        "            continue\n",
        "\n",
        "        images_folder = os.path.join(label_path, \"Images\")\n",
        "        if not os.path.isdir(images_folder):\n",
        "            continue\n",
        "\n",
        "        for image_file in os.listdir(images_folder):\n",
        "            if not image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                continue\n",
        "\n",
        "            full_image_path = os.path.join(images_folder, image_file)\n",
        "\n",
        "            test_img = cv2.imread(full_image_path)\n",
        "            if test_img is None:\n",
        "                print(f\"Skipping invalid image: {full_image_path}\")\n",
        "                continue  # skip to next image\n",
        "\n",
        "\n",
        "            image_rgb = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Convert to MediaPipe Image object\n",
        "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)\n",
        "\n",
        "            result = landmarker.detect(mp_image)\n",
        "\n",
        "            if result.pose_landmarks and len(result.pose_landmarks) > 0:\n",
        "                landmark_list = result.pose_landmarks[0]  # 1 person\n",
        "                landmarks = []\n",
        "                for lm in landmark_list:\n",
        "                    landmarks.extend([lm.x, lm.y, lm.z, lm.visibility])\n",
        "                X.append(landmarks)\n",
        "                y.append(label_folder)\n",
        "\n",
        "# Convert to arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Feature shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COTFbLcksKdK",
        "outputId": "f4bccea2-a533-4477-f549-a8c12fd50529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.35614049  0.46239594 -0.21268496  0.99991763  0.34732348  0.46317449\n",
            " -0.19650474  0.99988747  0.34739149  0.46180692 -0.19655327  0.99976844\n",
            "  0.34748888  0.4604857  -0.19662991  0.99980897  0.34655154  0.4700532\n",
            " -0.20822865  0.99993563  0.3458735   0.47401676 -0.20836335  0.99991286\n",
            "  0.34513178  0.47955954 -0.20835443  0.99991286  0.35056537  0.46947071\n",
            " -0.10418595  0.99981219  0.34690291  0.50305068 -0.15892996  0.9999187\n",
            "  0.36656022  0.46230638 -0.17770208  0.99984217  0.3655684   0.4723323\n",
            " -0.19353841  0.99990666  0.40174121  0.43724573 -0.06370167  0.99998701\n",
            "  0.3972159   0.56435937 -0.1158645   0.99996436  0.39970022  0.33423921\n",
            " -0.07111737  0.96530461  0.39857864  0.67586994 -0.15624148  0.98875779\n",
            "  0.39453667  0.2389296  -0.15579689  0.95139754  0.38452351  0.78856832\n",
            " -0.22632419  0.98145998  0.39222777  0.21197483 -0.17848668  0.89467818\n",
            "  0.38001657  0.8118248  -0.24293949  0.95548427  0.39079529  0.21093714\n",
            " -0.19959982  0.90009177  0.37805361  0.81118006 -0.2637139   0.9581092\n",
            "  0.39189571  0.21880281 -0.17259535  0.91400141  0.38022798  0.80215704\n",
            " -0.2395938   0.96238703  0.54186833  0.45999706 -0.00680598  0.99998856\n",
            "  0.52916139  0.5316202   0.00683379  0.99991775  0.65452516  0.47076192\n",
            " -0.00891093  0.99096453  0.53266996  0.67589629  0.01867004  0.93242216\n",
            "  0.74416953  0.47766355  0.08862735  0.97843552  0.52413726  0.84921092\n",
            "  0.12942807  0.90671992  0.75566697  0.4819006   0.09444129  0.90224987\n",
            "  0.53048295  0.86359727  0.13712606  0.84308374  0.77505153  0.4711948\n",
            "  0.00235212  0.94190925  0.49089479  0.88424283  0.07650679  0.82919234]\n"
          ]
        }
      ],
      "source": [
        "print(X[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wo03o_-gu47X"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # e.g., 'Tadasana' -> 0, 'Vrikshasana' -> 1\n",
        "np.save('label_encoder_classes.npy', label_encoder.classes_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded value 0 corresponds to: ArdhaChandrasana\n",
            "Encoded value 1 corresponds to: BaddhaKonasana\n",
            "Encoded value 2 corresponds to: Downward_dog\n",
            "Encoded value 3 corresponds to: Natarajasana\n",
            "Encoded value 4 corresponds to: Triangle\n",
            "Encoded value 5 corresponds to: UtkataKonasana\n",
            "Encoded value 6 corresponds to: Veerabhadrasana\n",
            "Encoded value 7 corresponds to: Vrukshasana\n"
          ]
        }
      ],
      "source": [
        "for i, pose_name in enumerate(label_encoder.classes_):\n",
        "    print(f\"Encoded value {i} corresponds to: {pose_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5u5qTeT92J_D"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeGqTHy62KEn",
        "outputId": "a81f649d-493b-4021-d9fb-8ddfb778eb1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\HP\\anaconda3\\envs\\pose_env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2000 - loss: 2.0059 - val_accuracy: 0.3814 - val_loss: 1.8232\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4947 - loss: 1.7564 - val_accuracy: 0.5361 - val_loss: 1.5827\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5604 - loss: 1.5152 - val_accuracy: 0.6495 - val_loss: 1.3828\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6913 - loss: 1.2773 - val_accuracy: 0.7423 - val_loss: 1.2018\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7436 - loss: 1.1120 - val_accuracy: 0.7113 - val_loss: 1.0541\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7629 - loss: 0.9896 - val_accuracy: 0.7010 - val_loss: 0.9739\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7815 - loss: 0.8633 - val_accuracy: 0.7835 - val_loss: 0.8449\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8213 - loss: 0.7547 - val_accuracy: 0.8041 - val_loss: 0.7424\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8142 - loss: 0.6997 - val_accuracy: 0.8351 - val_loss: 0.6672\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8562 - loss: 0.5988 - val_accuracy: 0.8763 - val_loss: 0.6075\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9035 - loss: 0.5686 - val_accuracy: 0.8454 - val_loss: 0.5878\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8450 - loss: 0.5397 - val_accuracy: 0.8763 - val_loss: 0.5156\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8860 - loss: 0.4930 - val_accuracy: 0.9072 - val_loss: 0.4788\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9240 - loss: 0.4338 - val_accuracy: 0.8351 - val_loss: 0.5056\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8925 - loss: 0.4113 - val_accuracy: 0.9175 - val_loss: 0.4193\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9189 - loss: 0.3606 - val_accuracy: 0.9485 - val_loss: 0.4037\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9077 - loss: 0.3478 - val_accuracy: 0.8763 - val_loss: 0.3728\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9296 - loss: 0.2828 - val_accuracy: 0.8660 - val_loss: 0.3695\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9234 - loss: 0.3197 - val_accuracy: 0.9175 - val_loss: 0.3339\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9255 - loss: 0.2921 - val_accuracy: 0.9278 - val_loss: 0.3137\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2b0a282a950>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(132,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(np.unique(y_encoded)), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_1um98B2KKA",
        "outputId": "7f87da4f-57cd-4733-aadd-08d4a0eb7580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9097 - loss: 0.3377 \n",
            "Validation accuracy: 0.9278350472450256\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# For neural net\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Validation accuracy:\", acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pYej9twe2KPi"
      },
      "outputs": [],
      "source": [
        "model.save(\"yoga_pose_model.keras\")\n",
        "#Saving the final trained model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pose_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
